---
title: "LBB-ML"
author: "MFFaqih"
date: "2023-03-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Import some libraries
```{r}
library(dplyr)
library(GGally)
library(lmtest)
library(car)
library(ggplot2)
library(MLmetrics)

```


#Read dataset
```{r}
house <- read.csv("HousePrices_HalfMil.csv")
head(house)
```


#Checking if there's any missiing values
```{r}
colSums(is.na(house))
```

#Checking columns data types
```{r}
glimpse(house)
```

# Find correlation between column
```{r}
ggcorr(house, label = TRUE, hjust = 1)
```


# Convert each column data type to it's appropriate type
```{r}
cols <- colnames(house)
cols
```

```{r}
house[cols] <- lapply(house[cols], factor)
house_clean <- house %>% 
  mutate(Garage = as.integer(Garage),
         FirePlace = as.integer(FirePlace),
         Baths = as.integer(Baths),
         Area = as.integer(Area),
         Prices = as.integer(Prices))
```


```{r}
glimpse(house_clean)
```

i convert garage, fire place and bath into INT data type instead of Factor, because its indicate level of value instead of boolean (yes/no)


```{r}
summary(house_clean)
```

From the data, we can conclude that (assuming theres no putliers and all the value is correct):
- Biggest house has area's wide of 249, and the smallest is 1
- The most expensive house price is 2714, and the cheapest is 1
- Most houses has, at least, 2 garage or 3 fireplaces or 3 baths


# Creating first model using columns that has strongest correlation with Prices column (> 0.4)
```{r}
model1 <- lm(Prices ~ Fiber + Floors, house_clean)
summary(model)
```

#Create second model using step wise elimination (regression)
```{r}
lm.all <- lm(Prices ~., house_clean)
model2 <- step(lm.all, direction = "backward")
summary(model2)
```


#LM assumption test

# 1. Normality
```{r}
hist(model1$residuals)
```

```{r}
hist(model2$residuals)
```

From normality test, both model has normal distribution.



# 2. heteroscedasticity

```{r}
bptest(model1)
```

```{r}
plot(resid(model1))
```


```{r}
bptest(model2)
```

```{r}
plot(resid(model2))
```

From our test above, we can conclude that only model 1 have heteroscedastisity (residual/error spreading randomly), even fro the plot, both model has random residual (heteroscedastisity).



# 3. Multicoliinearity

```{r}
vif(model1)
```


Since the second model has heteroscdasticity, we not further use the second value


# 4. Linearity

```{r}
plot(model1, 1)
```


# Checking Performance (model evaluation)


MAE( Mean Absolute Error)
```{r}
prediction <- predict(model1, house_clean)
MAE(y_pred = prediction, y_true = house_clean$Prices)
```


RMSE (Root Mean Squared Error)
```{r}
# Set seed for reproducibility
set.seed(123)

# Create index vector of row numbers
index <- sample(1:nrow(house_clean), size = floor(0.8 * nrow(house_clean)))

# Split data into train and test sets
data_train <- house_clean[index, ]
data_test <- house_clean[-index, ]
```

```{r}
# Model training
model_train <- lm(Prices ~ Fiber + Floors, data_train)

# Predict value
price_pred <- predict(model_train, newdata = data_test)
```

```{r}
#RMSE of train dataset
RMSE(y_pred = model_train$fitted.values, y_true = data_train$Prices)
```

```{r}
#RMSE of test dataset
RMSE(y_pred = price_pred, y_true = data_test$Prices)
```

CONCLUSION:
- From our model evaluation, we can conclude that the data is neither overfitted nor underfitted.

- Model1 has both R-squared and Adjusted R-squared of 61.2%.

- Both predicotr has positive correlation to house price. Any houses that has Fiber Design will have 468.6857 price higher, and any houses that has more floors will have 599.4866 price higher
